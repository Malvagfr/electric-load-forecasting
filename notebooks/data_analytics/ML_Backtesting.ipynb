{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07af2d1",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51157865",
   "metadata": {},
   "source": [
    "## Walk-forward backtesting methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65818e",
   "metadata": {},
   "source": [
    "- Baktesting is crucial for ensuring that a ML solution will be feasible in the future.\n",
    "- The idea is reproducing the behaviour in the past so it's possible to test that final solution will have a good perforance in the future.\n",
    "- With the daily electric market, traders value information about price,demand,generation...\n",
    "- One of the steps for predicting the final price is predict the demand before the markeyt opens (OMIE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263521aa",
   "metadata": {},
   "source": [
    "The code is launched every **day** at 11h using **day-1** data and giving as a result is the prediction of the **day+1**:\n",
    "- We have historical data from **2015 01 01 00:00h to 2021 31 12 23:00h** so we will do preditions **from 2016 to 2021::.\n",
    "- **Pred days**: moment the predition is launched (example 2016 01 01 11:00h) \n",
    "- **Begin forecast**: the moment the firt predition is set (2015 12 31 11:00h)\n",
    "- **End forecast**: the moment the last predition is set (2021 30 12 11:00h)\n",
    "- **Step**: predition frequency (1 day)\n",
    "- **Training frequency**: each month, we train the model with real data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8b13d0",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "134ccaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Libraries Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, date,timedelta\n",
    "from dateutil import tz\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ML model\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# error\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30728e11",
   "metadata": {},
   "source": [
    "## Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ca25e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "def read_csv(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4f7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date format\n",
    "def date_format(column,date_format):\n",
    "    return pd.to_datetime(column,format=date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e40eb1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "def drop_columns(df,columns):\n",
    "    return df.drop(columns, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "152d616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row filter\n",
    "def row_filter_limits(df, column,low_limit,high_limit):\n",
    "    return df[(df[column]>=low_limit)&(df[column]<=high_limit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33e3368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Timezone\n",
    "def change_timezone(datetime,from_zone,to_zone):\n",
    "    from_zone=tz.gettz(from_zone)\n",
    "    to_zone=tz.gettz(to_zone)\n",
    "    return datetime.replace(tzinfo=from_zone).astimezone(to_zone).replace(tzinfo=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21561c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join data\n",
    "def join_data(df_left,df_right,link_fields,link_type):\n",
    "    return pd.merge(df_left,df_right,on=link_fields,how=link_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34311705",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75db3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data \n",
    "df_electricity_demand=read_csv(\"../../data/intermediate_data/electricity_demand.csv\")\n",
    "\n",
    "# Drop not needed columns\n",
    "df_electricity_demand=drop_columns(df_electricity_demand,'Unnamed: 0')\n",
    "\n",
    "# Change time format\n",
    "df_electricity_demand['Time']=date_format(df_electricity_demand['Time'],\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d922a",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56f8da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "def craft_features(df,calendar_features=True,laglead_calendar_features=True,laglead_temperature=True,\n",
    "                  roll_temperature=True,daily_temp_features=True):\n",
    "    # Calendar features\n",
    "    if calendar_features:\n",
    "        df[\"Week_day\"]=df.Time.dt.day_name().astype('category').cat.codes\n",
    "        df['Week_day_category']=np.where(df[\"Time\"].dt.dayofweek>4,'Weekend','Week')\n",
    "        df['Week_day_category']=df['Week_day_category'].astype('category').cat.codes\n",
    "        df[\"Bank_Holiday_Weight\"]=df[\"Country_Bank_Holiday\"]+df[\"Partial_Bank_Holiday_Weight\"]\n",
    "\n",
    "        # Laglead calendar features\n",
    "        if laglead_calendar_features:\n",
    "            df[\"Bank_Holiday_Weight_p24\"]=df[\"Bank_Holiday_Weight\"].shift(24)\n",
    "            df[\"Bank_Holiday_Weight_n24\"]=df[\"Bank_Holiday_Weight\"].shift(-24)\n",
    "            df[\"Bank_Holiday_Weight_p168\"]=df[\"Bank_Holiday_Weight\"].shift(168)\n",
    "            df[\"Week_day_category_p24\"]=df[\"Week_day_category\"].shift(24)\n",
    "            df[\"Week_day_category_n24\"]=df[\"Week_day_category\"].shift(-24)\n",
    "\n",
    "    # Laglead Temperature \n",
    "    if laglead_temperature:\n",
    "            df[\"Temp_K_p1\"]=df[\"Temp_K\"].shift(1)     \n",
    "            df[\"Temp_K_p2\"]=df[\"Temp_K\"].shift(2)  \n",
    "\n",
    "            df[\"Temp_K_n1\"]=df[\"Temp_K\"].shift(-1)     \n",
    "            df[\"Temp_K_n2\"]=df[\"Temp_K\"].shift(-2)  \n",
    "\n",
    "            df[\"Temp_K_p24\"]=df[\"Temp_K\"].shift(24)       \n",
    "            df[\"Temp_K_p48\"]=df[\"Temp_K\"].shift(48)        \n",
    "            df[\"Temp_K_p72\"]=df[\"Temp_K\"].shift(72)               \n",
    "            df[\"Temp_K_p96\"]=df[\"Temp_K\"].shift(96)\n",
    "            df[\"Temp_K_p120\"]=df[\"Temp_K\"].shift(120)\n",
    "            df[\"Temp_K_p144\"]=df[\"Temp_K\"].shift(144)\n",
    "            df[\"Temp_K_p168\"]=df[\"Temp_K\"].shift(168)\n",
    "\n",
    "    # Rolling Statistical values\n",
    "    if roll_temperature:\n",
    "        df['Temp_K_SMA3']=df['Temp_K'].rolling(3,center=True).mean()\n",
    "        df['Temp_K_SMA5']=df['Temp_K'].rolling(5,center=True).mean()\n",
    "        df['Temp_K_SMA12']=df['Temp_K'].rolling(12,center=True).mean()\n",
    "\n",
    "        df['Temp_K_SD3']=df['Temp_K'].rolling(3,center=True).std()\n",
    "        df['Temp_K_SD5']=df['Temp_K'].rolling(5,center=True).std()\n",
    "        df['Temp_K_SD12']=df['Temp_K'].rolling(12,center=True).std()\n",
    "\n",
    "    # Statistical values by day\n",
    "    if daily_temp_features:\n",
    "        df_daily_temp=df.groupby(['Date'],as_index=False)\\\n",
    "        .agg(Daily_Temp_K_mean=('Temp_K', 'mean'),\n",
    "             Daily_Temp_K_std=('Temp_K','std'),\n",
    "             Daily_Temp_K_min=('Temp_K','min'),\n",
    "             Daily_Temp_K_max=('Temp_K','min')\n",
    "            )\n",
    "        df=join_data(df,df_daily_temp,'Date','left')\n",
    "\n",
    "        if laglead_temperature:\n",
    "            df_dailylag_temp=df.groupby(['Date'],as_index=False)\\\n",
    "            .agg(Daily_Temp_K_p24_mean=('Temp_K_p24', 'mean'),\n",
    "                 Daily_Temp_K_p24_std=('Temp_K_p24','std'),\n",
    "                 Daily_Temp_K_p24_min=('Temp_K_p24','min'),\n",
    "                 Daily_Temp_K_p24_max=('Temp_K_p24','min'),\n",
    "                 Daily_Temp_K_p168_mean=('Temp_K_p168', 'mean'),\n",
    "                 Daily_Temp_K_p168_std=('Temp_K_p168','std'),\n",
    "                 Daily_Temp_K_p168_min=('Temp_K_p168','min'),\n",
    "                 Daily_Temp_K_p168_max=('Temp_K_p168','min')\n",
    "            )\n",
    "            df=join_data(df,df_dailylag_temp,'Date','left')        \n",
    "\n",
    "    df=drop_columns(df,['Country_Bank_Holiday','Partial_Bank_Holiday','Partial_Bank_Holiday_Weight','Date',\n",
    "                       'Year','Day'])\n",
    "    df=df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e9ac5f",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09723c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "\n",
    "def get_xgb_model(df,section,target='Demand_MWh'):\n",
    "    df=drop_columns(df,'Time')\n",
    "    if section=='train':\n",
    "        X=drop_columns(df,target)\n",
    "        y=df[target]\n",
    "        # Split train and test\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        # Model\n",
    "        model_xgb=XGBRegressor(n_estimators=500,colsample_bylevel=1,colsample_bynode=1,\n",
    "                         colsample_bytree=0.8,reg_alpha=1, reg_lambda=1,\n",
    "                               gamma=0,learning_rate=0.1, random_state=42)\n",
    "        model_xgb.fit(X, y)\n",
    "        model_xgb.save_model(\"../../data/final_results/models/XGB_model.json\")\n",
    "\n",
    "    elif section=='predict':\n",
    "        model_xgb = XGBRegressor()\n",
    "        model_xgb.load_model(\"../../data/final_results/models/XGB_model.json\")\n",
    "        X_test=df\n",
    "        predictions=model_xgb.predict(X_test)\n",
    "        return predictions.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c7fc0",
   "metadata": {},
   "source": [
    "## Backtest calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff619c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters definition \n",
    "# Historical data starts in 2015 in UTC\n",
    "begin_training=datetime.strptime('2015-01-01 00:00:00', '%Y-%m-%d %H:%M:%S') \n",
    "\n",
    "# First forecast is set at the end of 2015 (so there is an historical year)\n",
    "# Forecast is launch each day at 11:00 o'clock in local time\n",
    "begin_forecast=datetime.strptime('2015-12-31 11:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "end_forecast=datetime.strptime('2021-12-29 11:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "end_forecast=datetime.strptime('2016-05-16 11:00:00', '%Y-%m-%d %H:%M:%S') #TO DELETE for testing purposes\n",
    "\n",
    "# Data is predicted everyday (24 hours)\n",
    "step=24 \n",
    "\n",
    "# Model is trained each month (30 days)\n",
    "training_frequency=30 \n",
    "\n",
    "# Timezone\n",
    "market_tz=\"Europe/Madrid\"\n",
    "data_tz='UTC'\n",
    "\n",
    "# Feature Engineerging params\n",
    "\n",
    "# Define lags\n",
    "max_X_lag=168\n",
    "max_X_lead=24\n",
    "\n",
    "calendar_features=True\n",
    "laglead_calendar_features=True\n",
    "laglead_temperature=True\n",
    "roll_temperature=True\n",
    "daily_temp_features=True\n",
    "predict_with_feedback=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4158656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model from:  2015-01-01 00:00:00  - to:  2015-12-30 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-01-28 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-02-27 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-03-28 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-04-27 23:00:00\n",
      "preditions:                      Time      Forecast  Demand_MWh\n",
      "0    2016-01-01 00:00:00  25062.693359  21745.1667\n",
      "1    2016-01-01 01:00:00  24121.230469  20483.3333\n",
      "2    2016-01-01 02:00:00  23386.531250  19246.3333\n",
      "3    2016-01-01 03:00:00  23309.117188  18358.1667\n",
      "4    2016-01-01 04:00:00  23469.003906  18057.3333\n",
      "...                  ...           ...         ...\n",
      "3204 2016-05-17 17:00:00  28581.966797  28299.5000\n",
      "3205 2016-05-17 18:00:00  28833.742188  28794.3333\n",
      "3206 2016-05-17 19:00:00  30323.824219  30063.0000\n",
      "3207 2016-05-17 20:00:00  29125.625000  29292.1667\n",
      "3208 2016-05-17 21:00:00  26914.845703  26571.0000\n",
      "\n",
      "[3209 rows x 3 columns]\n",
      "rmse:  1397.5097855448616\n",
      "mae:  987.2864455525474\n",
      "mae normalized:  3.4465442938213053  %\n",
      "CPU times: user 5min 49s, sys: 7.88 s, total: 5min 57s\n",
      "Wall time: 48.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Backtest calculation\n",
    "\n",
    "# define empty dataframe\n",
    "final_preds=pd.DataFrame()\n",
    "\n",
    "# Define predict times (each day at 11:00 during forecast period)\n",
    "pred_dates = pd.DataFrame({\"Pred_Date\": pd.date_range(begin_forecast, end_forecast)})\n",
    "\n",
    "# loop for predict everyday and train everymonth\n",
    "for index, row in pred_dates.iterrows():\n",
    "    \n",
    "    index=index+1\n",
    "    \n",
    "    # train section\n",
    "    if index % training_frequency == 0 or index==1:\n",
    "        section='train'\n",
    "        # end training is 23h of previous day (local time)\n",
    "        end_training=row['Pred_Date'].floor('d')-timedelta(hours = 1)\n",
    "\n",
    "        df_training=row_filter_limits(df_electricity_demand,'Time',begin_training,\n",
    "                                      change_timezone(end_training,market_tz,data_tz))\n",
    "        \n",
    "        df_training=craft_features(df_training,calendar_features,laglead_calendar_features,laglead_temperature,\n",
    "                                   roll_temperature,daily_temp_features)\n",
    "        \n",
    "        # Log\n",
    "        print('training model from: ',begin_training,' - to: ',end_training)\n",
    "        get_xgb_model(df_training,section)\n",
    "        \n",
    "    # Predict section\n",
    "    \n",
    "    section='predict'\n",
    "    \n",
    "    # Predit dates\n",
    "    # begin pred is next day at 00:00h local time\n",
    "    begin_pred=row['Pred_Date'].ceil('d')\n",
    "    # end pred is next day at 23:00h local time\n",
    "    end_pred=begin_pred+timedelta(days = 1)-timedelta(hours = 1)\n",
    "    \n",
    "    # Request dates: padding (including more times so lags/leads NA match with prediction)\n",
    "    # when going to prod, future prediction will need to be calculated\n",
    "    begin=begin_pred-timedelta(hours = max_X_lag)\n",
    "    end=end_pred+timedelta(hours = max_X_lead)\n",
    "    \n",
    "    if predict_with_feedback:\n",
    "        # TODO: recursive predition\n",
    "        print(row['Pred_Date'],begin_pred,end_pred)\n",
    "    else:\n",
    "        df_predict=df_electricity_demand.drop(columns=['Demand_MWh'])\n",
    "        \n",
    "        df_predict=row_filter_limits(df_electricity_demand,'Time',change_timezone(begin,market_tz,data_tz),\n",
    "                                     change_timezone(end,market_tz,data_tz))\n",
    "        # Feature engineering\n",
    "        df_predict=craft_features(df_predict,calendar_features,laglead_calendar_features,laglead_temperature,\n",
    "                                   roll_temperature,daily_temp_features)\n",
    "        \n",
    "        # Filtering data (removing extra lags/leads)\n",
    "        df_predict=row_filter_limits(df_predict,'Time',change_timezone(begin_pred,market_tz,data_tz),\n",
    "                                     change_timezone(end_pred,market_tz,data_tz))\n",
    "        # Prediction\n",
    "        df_predict=drop_columns(df_predict,'Demand_MWh') #removing the target in backtest\n",
    "        preds=get_xgb_model(df_predict,section)\n",
    "        \n",
    "        #concat time \n",
    "        test_preds=pd.concat([pd.DataFrame(df_predict['Time'].tolist()),pd.DataFrame(preds)],axis=1,ignore_index=True)\n",
    "        test_preds.columns = ['Time', 'Forecast']\n",
    "        \n",
    "    final_preds=final_preds.append(test_preds)\n",
    "    \n",
    "# Assessing (evaluation)\n",
    "final_results=pd.merge(final_preds,df_electricity_demand[['Time','Demand_MWh']],on=\"Time\",how=\"left\")\n",
    "final_results.to_csv(\"../../data/final_results/final_predictions.csv\")\n",
    "rmse_val = mean_squared_error(final_results['Demand_MWh'], final_results['Forecast'])**0.5\n",
    "mae_val=mean_absolute_error(final_results['Demand_MWh'], final_results['Forecast'])\n",
    "mae_normalized=mae_val/final_results['Demand_MWh'].mean()*100\n",
    "\n",
    "print('preditions: ',final_results)\n",
    "print('rmse: ',rmse_val)\n",
    "print('mae: ',mae_val)\n",
    "print('mae normalized: ',mae_normalized, ' %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:final-project]",
   "language": "python",
   "name": "conda-env-final-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
