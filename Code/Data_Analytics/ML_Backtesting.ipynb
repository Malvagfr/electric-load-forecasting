{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07af2d1",
   "metadata": {},
   "source": [
    "## ML Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44e796",
   "metadata": {},
   "source": [
    "El concepto backtest es crucial cuando evaluamos una previsión, una estrategia de trading... Ya que tenemos que reproducir su comportamiento en el pasado. En este caso estamos en el mercado eléctrico diario\n",
    "Antes de que se produzca la casación de OMIE, todos los sujectos de mercado deben saber la previsión diaría. Los traders pueden tener la información antes de que ocurra y actuar en consecuencia:\n",
    "\n",
    "- Precio\n",
    "- Demanda\n",
    "- Generación de los productores\n",
    "\n",
    "Una vez ocurre esto, se entraría en el mercado intradiario\n",
    "\n",
    "Intentamos anticipar la demanda que va a ocurrir en el mercado diario antes de que ocurra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c1a52",
   "metadata": {},
   "source": [
    "### Walk-forward back testing method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a15f49",
   "metadata": {},
   "source": [
    "- Lanzamos el código a las 11 de la mañana del dia d, la predición de d+1 basandose en los datos hasta d-1\n",
    "- Pred days: YYYY MM DD 11:00 (momento en el que se lanza la predicción, todas las 11 de la mañana de cada día)\n",
    "- Begin forecast: 2015 12 31 11:00h (día que se lanza la previsión para el día 1)\n",
    "- End forecast: 2021 30 12 11:00 (día que se lanza la previsión para el último día)\n",
    "- step: 1 día\n",
    "- Bucle a recorrer: momento de la precisión (pasos del bucle, steps)-> Begin forecast-End forecast\n",
    "- Training frequency: cada mes tenemos una tarea de entrenamiento del model (una vez sabemos el resultado de las medidas, entrenar, una vez al mes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6058bbec",
   "metadata": {},
   "source": [
    "### Modelo sin lags\n",
    "- Hacer las previsiones de golpe (asumimos que conocemos las temperaturas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127c725",
   "metadata": {},
   "source": [
    "### Modelo con lags\n",
    "- A las 11 de la mañana se han publicada la demanda real del día pasado\n",
    "- La técnica de predit: predict with feedback (recursive)\n",
    "- En cada pred date tenemos un gap de 11 horas desde el día pasado hasta la primera hora que querríamos predecir. La predición empieza a las 12 de la noche del día de predicción (predición pasada -1d hasta llegar al día d+1). Cada predicción se usa como medida para la siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8b13d0",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134ccaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Libraries Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, date,timedelta\n",
    "from dateutil import tz\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ML model\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# error\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30728e11",
   "metadata": {},
   "source": [
    "## Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca25e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "def read_csv(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4f7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date format\n",
    "def date_format(column,date_format):\n",
    "    return pd.to_datetime(column,format=date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40eb1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "def drop_columns(df,columns):\n",
    "    return df.drop(columns, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152d616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row filter\n",
    "def row_filter_limits(df, column,low_limit,high_limit):\n",
    "    return df[(df[column]>=low_limit)&(df[column]<=high_limit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33e3368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Timezone\n",
    "def change_timezone(datetime,from_zone,to_zone):\n",
    "    from_zone=tz.gettz(from_zone)\n",
    "    to_zone=tz.gettz(to_zone)\n",
    "    return datetime.replace(tzinfo=from_zone).astimezone(to_zone).replace(tzinfo=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21561c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join data\n",
    "def join_data(df_left,df_right,link_fields,link_type):\n",
    "    return pd.merge(df_left,df_right,on=link_fields,how=link_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34311705",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75db3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data \n",
    "df_electricity_demand=read_csv(\"../../Data/Intermediate_Data/electricity_demand.csv\")\n",
    "\n",
    "# Drop not needed columns\n",
    "df_electricity_demand=drop_columns(df_electricity_demand,'Unnamed: 0')\n",
    "\n",
    "# Change time format\n",
    "df_electricity_demand['Time']=date_format(df_electricity_demand['Time'],\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d922a",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56f8da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "#X=['Month','Hour','Demand_MWh','Temp_K','Country_Bank_Holiday','Partial_Bank_Holiday',\n",
    "   #'Partial_Bank_Holiday_Weight','Population']\n",
    "    \n",
    "def craft_features(df,calendar_features=True,laglead_calendar_features=True,laglead_temperature=True,\n",
    "                  roll_temperature=True,daily_temp_features=True):\n",
    "    # Calendar features\n",
    "    if calendar_features:\n",
    "        df[\"Week_day\"]=df.Time.dt.day_name().astype('category').cat.codes\n",
    "        df['Week_day_category']=np.where(df[\"Time\"].dt.dayofweek>4,'Weekend','Week')\n",
    "        df['Week_day_category']=df['Week_day_category'].astype('category').cat.codes\n",
    "        df[\"Bank_Holiday_Weight\"]=df[\"Country_Bank_Holiday\"]+df[\"Partial_Bank_Holiday_Weight\"]\n",
    "\n",
    "        # Laglead calendar features\n",
    "        if laglead_calendar_features:\n",
    "            df[\"Bank_Holiday_Weight_p24\"]=df[\"Bank_Holiday_Weight\"].shift(24)\n",
    "            df[\"Bank_Holiday_Weight_n24\"]=df[\"Bank_Holiday_Weight\"].shift(-24)\n",
    "            df[\"Bank_Holiday_Weight_p168\"]=df[\"Bank_Holiday_Weight\"].shift(168)\n",
    "            df[\"Week_day_category_p24\"]=df[\"Week_day_category\"].shift(24)\n",
    "            df[\"Week_day_category_n24\"]=df[\"Week_day_category\"].shift(-24)\n",
    "\n",
    "    # Laglead Temperature \n",
    "    if laglead_temperature:\n",
    "            df[\"Temp_K_p1\"]=df[\"Temp_K\"].shift(1)     \n",
    "            df[\"Temp_K_p2\"]=df[\"Temp_K\"].shift(2)  \n",
    "\n",
    "            df[\"Temp_K_n1\"]=df[\"Temp_K\"].shift(-1)     \n",
    "            df[\"Temp_K_n2\"]=df[\"Temp_K\"].shift(-2)  \n",
    "\n",
    "            df[\"Temp_K_p24\"]=df[\"Temp_K\"].shift(24)       \n",
    "            df[\"Temp_K_p48\"]=df[\"Temp_K\"].shift(48)        \n",
    "            df[\"Temp_K_p72\"]=df[\"Temp_K\"].shift(72)               \n",
    "            df[\"Temp_K_p96\"]=df[\"Temp_K\"].shift(96)\n",
    "            df[\"Temp_K_p120\"]=df[\"Temp_K\"].shift(120)\n",
    "            df[\"Temp_K_p144\"]=df[\"Temp_K\"].shift(144)\n",
    "            df[\"Temp_K_p168\"]=df[\"Temp_K\"].shift(168)\n",
    "\n",
    "    # Rolling Statistical values\n",
    "    if roll_temperature:\n",
    "        df['Temp_K_SMA3']=df['Temp_K'].rolling(3,center=True).mean()\n",
    "        df['Temp_K_SMA5']=df['Temp_K'].rolling(5,center=True).mean()\n",
    "        df['Temp_K_SMA12']=df['Temp_K'].rolling(12,center=True).mean()\n",
    "\n",
    "        df['Temp_K_SD3']=df['Temp_K'].rolling(3,center=True).std()\n",
    "        df['Temp_K_SD5']=df['Temp_K'].rolling(5,center=True).std()\n",
    "        df['Temp_K_SD12']=df['Temp_K'].rolling(12,center=True).std()\n",
    "\n",
    "    # Statistical values by day\n",
    "    if daily_temp_features:\n",
    "        df_daily_temp=df.groupby(['Date'],as_index=False)\\\n",
    "        .agg(Daily_Temp_K_mean=('Temp_K', 'mean'),\n",
    "             Daily_Temp_K_std=('Temp_K','std'),\n",
    "             Daily_Temp_K_min=('Temp_K','min'),\n",
    "             Daily_Temp_K_max=('Temp_K','min')\n",
    "            )\n",
    "        df=join_data(df,df_daily_temp,'Date','left')\n",
    "\n",
    "        if laglead_temperature:\n",
    "            df_dailylag_temp=df.groupby(['Date'],as_index=False)\\\n",
    "            .agg(Daily_Temp_K_p24_mean=('Temp_K_p24', 'mean'),\n",
    "                 Daily_Temp_K_p24_std=('Temp_K_p24','std'),\n",
    "                 Daily_Temp_K_p24_min=('Temp_K_p24','min'),\n",
    "                 Daily_Temp_K_p24_max=('Temp_K_p24','min'),\n",
    "                 Daily_Temp_K_p168_mean=('Temp_K_p168', 'mean'),\n",
    "                 Daily_Temp_K_p168_std=('Temp_K_p168','std'),\n",
    "                 Daily_Temp_K_p168_min=('Temp_K_p168','min'),\n",
    "                 Daily_Temp_K_p168_max=('Temp_K_p168','min')\n",
    "            )\n",
    "            df=join_data(df,df_dailylag_temp,'Date','left')        \n",
    "\n",
    "    df=drop_columns(df,['Country_Bank_Holiday','Partial_Bank_Holiday','Partial_Bank_Holiday_Weight','Date',\n",
    "                       'Year','Day'])\n",
    "    df=df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e9ac5f",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09723c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "\n",
    "def get_xgb_model(df,section,target='Demand_MWh'):\n",
    "    df=drop_columns(df,'Time')\n",
    "    if section=='train':\n",
    "        X=drop_columns(df,target)\n",
    "        y=df[target]\n",
    "        # Split train and test\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        # Model\n",
    "        model_xgb=XGBRegressor(n_estimators=500,colsample_bylevel=1,colsample_bynode=1,\n",
    "                         colsample_bytree=0.8,reg_alpha=1, reg_lambda=1,\n",
    "                               gamma=0,learning_rate=0.1, random_state=42)\n",
    "        model_xgb.fit(X, y)\n",
    "        model_xgb.save_model(\"../../Models/XGB_model.json\")\n",
    "\n",
    "    elif section=='predict':\n",
    "        model_xgb = XGBRegressor()\n",
    "        model_xgb.load_model(\"../../Models/XGB_model.json\")\n",
    "        X_test=df\n",
    "        predictions=model_xgb.predict(X_test)\n",
    "        return predictions.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c7fc0",
   "metadata": {},
   "source": [
    "## Backtest calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff619c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters definition \n",
    "\n",
    "# Historical data starts in 2015 in utc\n",
    "begin_training=datetime.strptime('2015-01-01 00:00:00', '%Y-%m-%d %H:%M:%S') \n",
    "\n",
    "# First forecast is set at the end of 2015 (so there is an historical year)\n",
    "# Forecast is launch each day at 11:00 o'clock in local time\n",
    "begin_forecast=datetime.strptime('2015-12-31 11:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "end_forecast=datetime.strptime('2021-12-29 11:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "#end_forecast=datetime.strptime('2016-05-16 11:00:00', '%Y-%m-%d %H:%M:%S') #TO DELETE for testing purposes\n",
    "\n",
    "# Data is predicted everyday (24 hours)\n",
    "step=24 \n",
    "\n",
    "# Model is trained each month (30 days)\n",
    "training_frequency=30 \n",
    "\n",
    "# It exists the possibility of use past data or only external data as feature (lags)\n",
    "predict_with_feedback=False\n",
    "\n",
    "# Timezone\n",
    "market_tz=\"Europe/Madrid\"\n",
    "data_tz='UTC'\n",
    "\n",
    "# Feature Engineerging params\n",
    "\n",
    "# Define lags\n",
    "max_X_lag=168\n",
    "max_X_lead=24\n",
    "\n",
    "calendar_features=True\n",
    "laglead_calendar_features=True\n",
    "laglead_temperature=True\n",
    "roll_temperature=True\n",
    "daily_temp_features=True\n",
    "raw=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4158656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model from:  2015-01-01 00:00:00  - to:  2015-12-30 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-01-28 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-02-27 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-03-28 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-04-27 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-05-27 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-06-26 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-07-26 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-08-25 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-09-24 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-10-24 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-11-23 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2016-12-23 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-01-22 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-02-21 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-03-23 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-04-22 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-05-22 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-06-21 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-07-21 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-08-20 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-09-19 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-10-19 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-11-18 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2017-12-18 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-01-17 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-02-16 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-03-18 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-04-17 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-05-17 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-06-16 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-07-16 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-08-15 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-09-14 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-10-14 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-11-13 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2018-12-13 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-01-12 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-02-11 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-03-13 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-04-12 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-05-12 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-06-11 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-07-11 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-08-10 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-09-09 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-10-09 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-11-08 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2019-12-08 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-01-07 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-02-06 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-03-07 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-04-06 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-05-06 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-06-05 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-07-05 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-08-04 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-09-03 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-10-03 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-11-02 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2020-12-02 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-01-01 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-01-31 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-03-02 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-04-01 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-05-01 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-05-31 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-06-30 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-07-30 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-08-29 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-09-28 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-10-28 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-11-27 23:00:00\n",
      "training model from:  2015-01-01 00:00:00  - to:  2021-12-27 23:00:00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/final-project/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5498\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5499\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5501\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5502\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/final-project/lib/python3.7/site-packages/pandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/final-project/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/final-project/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/final-project/lib/python3.7/site-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             raise ValueError(\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Backtest calculation\n",
    "\n",
    "# define empty dataframe\n",
    "final_preds=pd.DataFrame()\n",
    "\n",
    "# Define predict times (each day at 11:00 during forecast period)\n",
    "pred_dates = pd.DataFrame({\"Pred_Date\": pd.date_range(begin_forecast, end_forecast)})\n",
    "\n",
    "# loop for predict everyday and train everymonth\n",
    "for index, row in pred_dates.iterrows():\n",
    "    \n",
    "    index=index+1\n",
    "    \n",
    "    # train section\n",
    "    if index % training_frequency == 0 or index==1:\n",
    "        section='train'\n",
    "        # end training is 23h of previous day (local time)\n",
    "        end_training=row['Pred_Date'].floor('d')-timedelta(hours = 1)\n",
    "\n",
    "        df_training=row_filter_limits(df_electricity_demand,'Time',begin_training,\n",
    "                                      change_timezone(end_training,market_tz,data_tz))\n",
    "        \n",
    "        df_training=craft_features(df_training,calendar_features,laglead_calendar_features,laglead_temperature,\n",
    "                                   roll_temperature,daily_temp_features)\n",
    "        \n",
    "        # Log\n",
    "        print('training model from: ',begin_training,' - to: ',end_training)\n",
    "        get_xgb_model(df_training,section)\n",
    "        \n",
    "    # Predict section\n",
    "    \n",
    "    section='predict'\n",
    "    \n",
    "    # Predit dates\n",
    "    begin_pred=row['Pred_Date'].ceil('d')\n",
    "    end_pred=begin_pred+timedelta(days = 1)-timedelta(hours = 1)\n",
    "    \n",
    "    # Request dates: padding (including more times so lags/leads NA match with prediction)\n",
    "    begin=begin_pred-timedelta(hours = max_X_lag)\n",
    "    end=end_pred+timedelta(hours = max_X_lead)\n",
    "    \n",
    "    if predict_with_feedback:\n",
    "        # TODO: recursive predition\n",
    "        print(row['Pred_Date'],begin_pred,end_pred)\n",
    "    else:\n",
    "        df_predict=df_electricity_demand.drop(columns=['Demand_MWh'])\n",
    "        \n",
    "        df_predict=row_filter_limits(df_electricity_demand,'Time',change_timezone(begin,market_tz,data_tz),\n",
    "                                     change_timezone(end,market_tz,data_tz))\n",
    "        # Feature engineering\n",
    "        df_predict=craft_features(df_predict,calendar_features,laglead_calendar_features,laglead_temperature,\n",
    "                                   roll_temperature,daily_temp_features)\n",
    "        \n",
    "        # Filtering data\n",
    "        df_predict=row_filter_limits(df_predict,'Time',change_timezone(begin_pred,market_tz,data_tz),\n",
    "                                     change_timezone(end_pred,market_tz,data_tz))\n",
    "        # Prediction\n",
    "        df_predict=drop_columns(df_predict,'Demand_MWh') #removing the target in backtest\n",
    "        preds=get_xgb_model(df_predict,section)\n",
    "        \n",
    "        test_preds=pd.concat([pd.DataFrame(df_predict['Time'].tolist()),pd.DataFrame(preds)],axis=1,ignore_index=True)\n",
    "        test_preds.columns = ['Time', 'Forecast']\n",
    "        \n",
    "    final_preds=final_preds.append(test_preds)\n",
    "    \n",
    "# Assessing (evaluation)\n",
    "final_results=pd.merge(final_preds,df_electricity_demand[['Time','Demand_MWh']],on=\"Time\",how=\"left\")\n",
    "final_results.to_csv(\"../../Data/final_results.csv\")\n",
    "rmse_val = mean_squared_error(final_results['Demand_MWh'], final_results['Forecast'])**0.5\n",
    "mae_val=mean_absolute_error(final_results['Demand_MWh'], final_results['Forecast'])\n",
    "mae_normalized=mae_val/final_results['Demand_MWh'].mean()*100\n",
    "\n",
    "print('preditions: ',final_results)\n",
    "print('rmse: ',rmse_val)\n",
    "print('mae: ',mae_val)\n",
    "print('mae normalized: ',mae_normalized, ' %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:final-project]",
   "language": "python",
   "name": "conda-env-final-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
